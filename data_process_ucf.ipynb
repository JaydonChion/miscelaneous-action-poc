{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import glob\n",
    "import cv2\n",
    "d={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "(1, 20, 28, 28, 3)\n"
     ]
    }
   ],
   "source": [
    "data_dir='UCF-101/*/*'\n",
    "data_list=glob.glob(data_dir)\n",
    "img_size=(28,28)\n",
    "frame_number=20\n",
    "sample_step=4\n",
    "data=np.empty([1,frame_number,img_size[0],img_size[1],3])\n",
    "label=np.empty([1,])\n",
    "fps=25\n",
    "sample_step=4\n",
    "npz_order=0\n",
    "num_cat = 4\n",
    "video_per_cat=60\n",
    "\n",
    "\n",
    "print(len(data_list))\n",
    "print(data.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"classInd.txt\") as f:\n",
    "    for line in f:\n",
    "       (key, val) = line.split()\n",
    "       d[int(key)-1] = val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_array = np.zeros((num_cat*video_per_cat,num_cat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "videonumkeeptrack = np.zeros((1,num_cat))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 talkdata/notchatting/notchatting.mp4\n",
      "[[0. 1.]]\n",
      "talkdata/notchatting/notchatting.mp4\n",
      "1 talkdata/talking/Talking.mp4\n",
      "[[1. 1.]]\n",
      "talkdata/talking/Talking.mp4\n",
      "data shape；(17, 20, 28, 28, 3)\n"
     ]
    }
   ],
   "source": [
    "arraynum = 0\n",
    "for num, video in enumerate(data_list):\n",
    "    read_video = False\n",
    "    print (num, video)\n",
    "    if(not arraynum<(num_cat*video_per_cat)):\n",
    "        break\n",
    "    for key, videoname in d.items():    # for name, age in dictionary.iteritems():  (for Python 2.x)\n",
    "        if (videoname in video) and (key<num_cat):\n",
    "            if(videonumkeeptrack[0][key]<video_per_cat):\n",
    "                videonumkeeptrack[0][key] = videonumkeeptrack[0][key]+1\n",
    "                print(videonumkeeptrack)\n",
    "                print(video)\n",
    "                read_video = True\n",
    "                one_hot_array[arraynum][key]=1\n",
    "                arraynum = arraynum+1\n",
    "    if(read_video):\n",
    "        cap = cv2.VideoCapture(video)\n",
    "        #fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "        total_frame=cap.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "        #print(total_frame)\n",
    "        sample=np.empty([1,1,img_size[0],img_size[1],3])\n",
    "        for i in range(sample_step*frame_number):\n",
    "            if (i%sample_step)==0:\n",
    "                ret, frame = cap.read()\n",
    "                if ret==False:\n",
    "                    prev=sample[0,-1].reshape(1,1,img_size[0],img_size[1],3)\n",
    "                    sample=np.append(sample,prev,axis=1)\n",
    "                else:\n",
    "                    cropped_frame=cv2.resize(frame,(img_size[0],img_size[1]))\n",
    "                    cropped_frame=cropped_frame.reshape(1,1,img_size[0],img_size[1],3)\n",
    "                    sample=np.append(sample,cropped_frame,axis=1)\n",
    "        sample=sample[0,1:]\n",
    "        sample=sample.reshape([1,frame_number,img_size[0],img_size[1],3])\n",
    "        #print(\"one sample shape: {}\".format(sample.shape))\n",
    "        data=np.append(data,sample,axis=0)\n",
    "#         del sample,cropped_frame\n",
    "\n",
    "\n",
    "\n",
    "print(\"data shape；{}\".format(data.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'raw_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-29a50bd6206c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# print(boundary)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# raw_data = data[:boundary,...]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mraw_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mraw_data\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m255.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'raw_data' is not defined"
     ]
    }
   ],
   "source": [
    "boundary = num_cat*video_per_cat\n",
    "print(boundary)\n",
    "raw_data = data[:boundary,...]\n",
    "raw_data = raw_data/255.0\n",
    "print(raw_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(240, 2)\n"
     ]
    }
   ],
   "source": [
    "print(raw_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "index=np.arange(len(one_hot_array))\n",
    "np.random.shuffle(index)\n",
    "print (index)\n",
    "raw_data=raw_data[index]\n",
    "one_hot_array=one_hot_array[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez_compressed('npz_data/ucf_classes/data_{}_{}.npz'.format(npz_order,img_size[0]), arr_0=raw_data)\n",
    "np.savez_compressed('npz_data/ucf_classes/label_{}_{}.npz'.format(npz_order,img_size[0]), arr_0=one_hot_array)\n",
    "#npz_order+=1\n",
    "raw_data=np.empty([1,frame_number,img_size[0],img_size[1],3])\n",
    "one_hot_array=np.empty([1,num_cat])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(raw_data.shape)\n",
    "print(one_hot_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
