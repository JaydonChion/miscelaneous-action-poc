{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# import tensorflow.compat.v1 as tf\n",
    "# tf.disable_v2_behavior()\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "import sys  \n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import model_selection\n",
    "from sklearn import preprocessing\n",
    "import tensorflow as tf\n",
    "import scipy\n",
    "\n",
    "from numpy import argmax\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.13.1\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)\n",
    "data_path=\"npz_data/violence/*\"\n",
    "# data_path2=\"npz_data/testtalk/*\"\n",
    "\n",
    "img_size=(224,224,3)\n",
    "frame_number=20\n",
    "num_class=2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(294, 20, 28, 28, 3)\n",
      "(294, 20, 224, 224, 3)\n",
      "(294, 20, 224, 224, 3)\n",
      "(294, 2)\n"
     ]
    }
   ],
   "source": [
    "def load_data(data_path):\n",
    "    data=np.empty([1,frame_number,img_size[0],img_size[1],3])\n",
    "    label=np.empty([1,num_class])\n",
    "    file_list=glob.glob(data_path)\n",
    "    data_list=[d for d in file_list if \"data\" in d.split(\"/\")[-1]]\n",
    "    label_list=[l for l in file_list if \"label\" in l.split(\"/\")[-1]]\n",
    "#     for index in range(len(data_list)):\n",
    "#         d=np.load(data_list[index])[\"arr_0\"]\n",
    "#         l=np.load(label_list[index])[\"arr_0\"]\n",
    "#         data=np.append(data,d,axis=0)\n",
    "#         data=np.append(label,l,axis=0)\n",
    "#     data=data[1:]\n",
    "#     label=label[1:]\n",
    "    for index in range(len(data_list)):\n",
    "        data=np.load(data_list[index])[\"arr_0\"]\n",
    "        label=np.load(label_list[index])[\"arr_0\"]\n",
    "    return data,label\n",
    "\n",
    "data,label=load_data(data_path)\n",
    "\n",
    "print(data.shape)\n",
    "\n",
    "#try to upsize the data\n",
    "sample=np.empty([len(data),frame_number,img_size[0],img_size[1],3])\n",
    "\n",
    "print(sample.shape)\n",
    "\n",
    "for frameCubeNum in range(len(data)):\n",
    "    frameCube = data[frameCubeNum,...]\n",
    "    frame_stack=np.empty([frame_number,img_size[0],img_size[1],3])\n",
    "#     print(\"size of frame cube {}\".format(frame_stack.shape))\n",
    "\n",
    "    for imgcubeNum in range(len(frameCube)):\n",
    "        imgcube = frameCube[imgcubeNum,...]\n",
    "        img_stack=np.empty([img_size[0],img_size[1],3])\n",
    "#         print(\"size of imgcube cube {}\".format(img_stack.shape))\n",
    "\n",
    "        for imglayerNum in range(3):\n",
    "            imglayer = imgcube[...,imglayerNum]\n",
    "            img_sm = cv2.resize(imglayer, (img_size[0],img_size[1]), interpolation=cv2.INTER_CUBIC)\n",
    "#             print(\"size of imglayer {}\".format(imglayer.shape))\n",
    "            img_stack[...,imglayerNum] = img_sm\n",
    "        \n",
    "        frame_stack[imgcubeNum,...]=img_stack\n",
    "#         frame_stack=np.append(frame_stack,img_stack,axis=0)\n",
    "#         print(frameCube.shape)\n",
    "        \n",
    "    sample[frameCubeNum,...]=frame_stack\n",
    "    \n",
    "    \n",
    "    \n",
    "data = sample\n",
    "\n",
    "print(data.shape)\n",
    "print(label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #load extra test data\n",
    "# def load_test_data(data_path):\n",
    "#     data=np.empty([1,frame_number,img_size[0],img_size[1],3])\n",
    "#     label=np.empty([1,num_class])\n",
    "#     file_list=glob.glob(data_path)\n",
    "#     data_list=[d for d in file_list if \"data\" in d.split(\"/\")[-1]]\n",
    "#     label_list=[l for l in file_list if \"label\" in l.split(\"/\")[-1]]\n",
    "# #     for index in range(len(data_list)):\n",
    "# #         d=np.load(data_list[index])[\"arr_0\"]\n",
    "# #         l=np.load(label_list[index])[\"arr_0\"]\n",
    "# #         data=np.append(data,d,axis=0)\n",
    "# #         data=np.append(label,l,axis=0)\n",
    "# #     data=data[1:]\n",
    "# #     label=label[1:]\n",
    "#     for index in range(len(data_list)):\n",
    "#         data=np.load(data_list[index])[\"arr_0\"]\n",
    "#         label=np.load(label_list[index])[\"arr_0\"]\n",
    "#     return data,label\n",
    "\n",
    "# test2data,test2label=load_test_data(data_path2)\n",
    "\n",
    "# print(test2data.shape)\n",
    "\n",
    "# #try to upsize the data\n",
    "# sample2=np.empty([len(test2data),frame_number,img_size[0],img_size[1],3])\n",
    "\n",
    "# print(sample2.shape)\n",
    "\n",
    "# for frameCubeNum in range(len(test2data)):\n",
    "#     frameCube = test2data[frameCubeNum,...]\n",
    "#     frame_stack=np.empty([frame_number,img_size[0],img_size[1],3])\n",
    "# #     print(\"size of frame cube {}\".format(frame_stack.shape))\n",
    "\n",
    "#     for imgcubeNum in range(len(frameCube)):\n",
    "#         imgcube = frameCube[imgcubeNum,...]\n",
    "#         img_stack=np.empty([img_size[0],img_size[1],3])\n",
    "# #         print(\"size of imgcube cube {}\".format(img_stack.shape))\n",
    "\n",
    "#         for imglayerNum in range(3):\n",
    "#             imglayer = imgcube[...,imglayerNum]\n",
    "#             img_sm = cv2.resize(imglayer, (img_size[0],img_size[1]), interpolation=cv2.INTER_CUBIC)\n",
    "# #             print(\"size of imglayer {}\".format(imglayer.shape))\n",
    "#             img_stack[...,imglayerNum] = img_sm\n",
    "        \n",
    "#         frame_stack[imgcubeNum,...]=img_stack\n",
    "# #         frame_stack=np.append(frame_stack,img_stack,axis=0)\n",
    "# #         print(frameCube.shape)\n",
    "        \n",
    "#     sample2[frameCubeNum,...]=frame_stack\n",
    "    \n",
    "    \n",
    "    \n",
    "# test2data = sample2\n",
    "\n",
    "# print(test2data.shape)\n",
    "# print(test2label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_x = data[:int(label.shape[0]*0.8),...]\n",
    "# train_y = label[:int(label.shape[0]*0.8),...]\n",
    "# valid_x = data[int(label.shape[0]*0.8):int(label.shape[0]*0.9),...]\n",
    "# valid_y = label[int(label.shape[0]*0.8):int(label.shape[0]*0.9),...]\n",
    "# test_x = data[int(label.shape[0]*0.9):,...]\n",
    "# test_y = label[int(label.shape[0]*0.9):,...]\n",
    "\n",
    "train_x, valid_x, train_y,valid_y =  train_test_split(data, label, test_size=0.5,random_state=42)\n",
    "test_x, valid_x, test_y,valid_y =  train_test_split(valid_x, valid_y, test_size=0.5, random_state=42)\n",
    "\n",
    "del data,label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(73, 2)\n"
     ]
    }
   ],
   "source": [
    "print(test_y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0514 17:35:35.688138 140397181781760 __init__.py:56] Some hub symbols are not available because TensorFlow version is less than 1.14\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_hub as hub\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/jetherng/keras/lib/python3.5/site-packages/tensorflow/python/ops/control_flow_ops.py:3632: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0514 17:35:37.594489 140397181781760 deprecation.py:323] From /home/jetherng/keras/lib/python3.5/site-packages/tensorflow/python/ops/control_flow_ops.py:3632: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0514 17:35:38.936826 140397181781760 saver.py:1483] Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-8-a8abe9461434>:9: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0514 17:35:39.012495 140397181781760 deprecation.py:323] From <ipython-input-8-a8abe9461434>:9: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-8-a8abe9461434>:10: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0514 17:35:39.024795 140397181781760 deprecation.py:506] From <ipython-input-8-a8abe9461434>:10: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-8-a8abe9461434>:22: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0514 17:35:39.055184 140397181781760 deprecation.py:323] From <ipython-input-8-a8abe9461434>:22: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# learning_rate = 1e-6\n",
    "X = tf.placeholder(tf.float32,[None,frame_number,224,224,3])\n",
    "labels = tf.placeholder(tf.float32,[None,num_class])\n",
    "\n",
    "\n",
    "module = hub.Module(\"https://tfhub.dev/deepmind/i3d-kinetics-600/1\",trainable=False)\n",
    "outputs = module(X)\n",
    "\n",
    "dense1 = tf.layers.dense(inputs=outputs, units=128)\n",
    "dropped1 = tf.nn.dropout(dense1,keep_prob=0.5)\n",
    "dense2 = tf.layers.dense(inputs=dropped1, units=128)\n",
    "dropped2 = tf.nn.dropout(dense2,keep_prob=0.5)\n",
    "# dense2 = tf.layers.dense(inputs=dense1, units=128)\n",
    "# dense3 = tf.layers.dense(inputs=dense2, units=128)\n",
    "\n",
    "logits = tf.layers.dense(inputs=dropped2, units=num_class)\n",
    "\n",
    "prediction = tf.nn.softmax(logits)\n",
    "\n",
    "# Define loss and optimizer\n",
    "loss_op = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
    "    logits=logits, labels=labels))\n",
    "optimizer = tf.train.AdamOptimizer()\n",
    "train_op = optimizer.minimize(loss_op)\n",
    "        \n",
    "correct_pred = tf.equal(tf.argmax(prediction, 1), tf.argmax(labels, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0\n",
      "Step 0, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Step 1, Minibatch Loss= 89.4407, Training Accuracy= 0.333\n",
      "Step 2, Minibatch Loss= 196.6114, Training Accuracy= 0.750\n",
      "Step 4, Minibatch Loss= 146.8102, Training Accuracy= 0.667\n",
      "Step 6, Minibatch Loss= 218.0002, Training Accuracy= 0.625\n",
      "Step 8, Minibatch Loss= 337.5642, Training Accuracy= 0.500\n",
      "Step 10, Minibatch Loss= 216.3310, Training Accuracy= 0.500\n",
      "Step 12, Minibatch Loss= 620.8678, Training Accuracy= 0.357\n",
      "Step 14, Minibatch Loss= 227.2975, Training Accuracy= 0.562\n",
      "Step 16, Minibatch Loss= 330.6172, Training Accuracy= 0.500\n",
      "Step 18, Minibatch Loss= 322.5207, Training Accuracy= 0.600\n",
      "Step 20, Minibatch Loss= 315.7881, Training Accuracy= 0.455\n",
      "Step 22, Minibatch Loss= 88.8907, Training Accuracy= 0.708\n",
      "Step 24, Minibatch Loss= 198.0201, Training Accuracy= 0.692\n",
      "Step 26, Minibatch Loss= 125.2279, Training Accuracy= 0.643\n",
      "Step 28, Minibatch Loss= 320.8257, Training Accuracy= 0.367\n",
      "Step 30, Minibatch Loss= 181.1575, Training Accuracy= 0.625\n",
      "Step 32, Minibatch Loss= 128.6356, Training Accuracy= 0.559\n",
      "Step 34, Minibatch Loss= 181.8511, Training Accuracy= 0.472\n",
      "Step 36, Minibatch Loss= 179.7383, Training Accuracy= 0.474\n",
      "Step 38, Minibatch Loss= 187.8311, Training Accuracy= 0.425\n",
      "Step 40, Minibatch Loss= 195.8483, Training Accuracy= 0.405\n",
      "Step 42, Minibatch Loss= 196.1392, Training Accuracy= 0.318\n",
      "Step 44, Minibatch Loss= 112.4554, Training Accuracy= 0.413\n",
      "Step 46, Minibatch Loss= 145.8023, Training Accuracy= 0.458\n",
      "Step 48, Minibatch Loss= 133.8660, Training Accuracy= 0.500\n",
      "Step 50, Minibatch Loss= 89.2356, Training Accuracy= 0.596\n",
      "Step 52, Minibatch Loss= 100.8189, Training Accuracy= 0.444\n",
      "Step 54, Minibatch Loss= 85.7859, Training Accuracy= 0.393\n",
      "Step 56, Minibatch Loss= 108.9917, Training Accuracy= 0.397\n",
      "Step 58, Minibatch Loss= 86.2146, Training Accuracy= 0.533\n",
      "Step 60, Minibatch Loss= 75.5228, Training Accuracy= 0.435\n",
      "Step 62, Minibatch Loss= 43.5054, Training Accuracy= 0.547\n",
      "Step 64, Minibatch Loss= 46.8430, Training Accuracy= 0.591\n",
      "Step 66, Minibatch Loss= 38.9620, Training Accuracy= 0.588\n",
      "Step 68, Minibatch Loss= 47.6038, Training Accuracy= 0.643\n",
      "Step 70, Minibatch Loss= 62.9386, Training Accuracy= 0.528\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[74,64,10,112,112] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node module_apply_default/RGB/inception_i3d/Conv3d_1a_7x7/conv_3d/convolution (defined at /home/jetherng/keras/lib/python3.5/site-packages/tensorflow_hub/native_module.py:547) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\nCaused by op 'module_apply_default/RGB/inception_i3d/Conv3d_1a_7x7/conv_3d/convolution', defined at:\n  File \"/usr/lib/python3.5/runpy.py\", line 184, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/jetherng/keras/lib/python3.5/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/jetherng/keras/lib/python3.5/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/jetherng/keras/lib/python3.5/site-packages/ipykernel/kernelapp.py\", line 505, in start\n    self.io_loop.start()\n  File \"/home/jetherng/keras/lib/python3.5/site-packages/tornado/platform/asyncio.py\", line 148, in start\n    self.asyncio_loop.run_forever()\n  File \"/usr/lib/python3.5/asyncio/base_events.py\", line 345, in run_forever\n    self._run_once()\n  File \"/usr/lib/python3.5/asyncio/base_events.py\", line 1312, in _run_once\n    handle._run()\n  File \"/usr/lib/python3.5/asyncio/events.py\", line 125, in _run\n    self._callback(*self._args)\n  File \"/home/jetherng/keras/lib/python3.5/site-packages/tornado/ioloop.py\", line 690, in <lambda>\n    lambda f: self._run_callback(functools.partial(callback, future))\n  File \"/home/jetherng/keras/lib/python3.5/site-packages/tornado/ioloop.py\", line 743, in _run_callback\n    ret = callback()\n  File \"/home/jetherng/keras/lib/python3.5/site-packages/tornado/gen.py\", line 781, in inner\n    self.run()\n  File \"/home/jetherng/keras/lib/python3.5/site-packages/tornado/gen.py\", line 742, in run\n    yielded = self.gen.send(value)\n  File \"/home/jetherng/keras/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 357, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"/home/jetherng/keras/lib/python3.5/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/home/jetherng/keras/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 267, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"/home/jetherng/keras/lib/python3.5/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/home/jetherng/keras/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 534, in execute_request\n    user_expressions, allow_stdin,\n  File \"/home/jetherng/keras/lib/python3.5/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/home/jetherng/keras/lib/python3.5/site-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/jetherng/keras/lib/python3.5/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/jetherng/keras/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2848, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/home/jetherng/keras/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2874, in _run_cell\n    return runner(coro)\n  File \"/home/jetherng/keras/lib/python3.5/site-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/home/jetherng/keras/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 3049, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/jetherng/keras/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 3214, in run_ast_nodes\n    if (yield from self.run_code(code, result)):\n  File \"/home/jetherng/keras/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 3296, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-8-a8abe9461434>\", line 7, in <module>\n    outputs = module(X)\n  File \"/home/jetherng/keras/lib/python3.5/site-packages/tensorflow_hub/module.py\", line 250, in __call__\n    name=name)\n  File \"/home/jetherng/keras/lib/python3.5/site-packages/tensorflow_hub/native_module.py\", line 547, in create_apply_graph\n    import_scope=relative_scope_name)\n  File \"/home/jetherng/keras/lib/python3.5/site-packages/tensorflow/python/training/saver.py\", line 1435, in import_meta_graph\n    meta_graph_or_file, clear_devices, import_scope, **kwargs)[0]\n  File \"/home/jetherng/keras/lib/python3.5/site-packages/tensorflow/python/training/saver.py\", line 1457, in _import_meta_graph_with_return_elements\n    **kwargs))\n  File \"/home/jetherng/keras/lib/python3.5/site-packages/tensorflow/python/framework/meta_graph.py\", line 806, in import_scoped_meta_graph_with_return_elements\n    return_elements=return_elements)\n  File \"/home/jetherng/keras/lib/python3.5/site-packages/tensorflow/python/util/deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"/home/jetherng/keras/lib/python3.5/site-packages/tensorflow/python/framework/importer.py\", line 442, in import_graph_def\n    _ProcessNewOps(graph)\n  File \"/home/jetherng/keras/lib/python3.5/site-packages/tensorflow/python/framework/importer.py\", line 235, in _ProcessNewOps\n    for new_op in graph._add_new_tf_operations(compute_devices=False):  # pylint: disable=protected-access\n  File \"/home/jetherng/keras/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 3433, in _add_new_tf_operations\n    for c_op in c_api_util.new_tf_operations(self)\n  File \"/home/jetherng/keras/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 3433, in <listcomp>\n    for c_op in c_api_util.new_tf_operations(self)\n  File \"/home/jetherng/keras/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 3325, in _create_op_from_tf_operation\n    ret = Operation(c_op, self)\n  File \"/home/jetherng/keras/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 1801, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[74,64,10,112,112] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node module_apply_default/RGB/inception_i3d/Conv3d_1a_7x7/conv_3d/convolution (defined at /home/jetherng/keras/lib/python3.5/site-packages/tensorflow_hub/native_module.py:547) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m~/keras/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/keras/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/keras/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[74,64,10,112,112] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node module_apply_default/RGB/inception_i3d/Conv3d_1a_7x7/conv_3d/convolution}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-e19fd9ea089f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                 \u001b[0;31m# Run optimization op (backprop)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m             \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_y\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdisplay_step\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                     \u001b[0;31m# Calculate batch loss and accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/keras/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/keras/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/keras/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/keras/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1346\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1347\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merror_interpolation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1348\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1350\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[74,64,10,112,112] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node module_apply_default/RGB/inception_i3d/Conv3d_1a_7x7/conv_3d/convolution (defined at /home/jetherng/keras/lib/python3.5/site-packages/tensorflow_hub/native_module.py:547) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\nCaused by op 'module_apply_default/RGB/inception_i3d/Conv3d_1a_7x7/conv_3d/convolution', defined at:\n  File \"/usr/lib/python3.5/runpy.py\", line 184, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/jetherng/keras/lib/python3.5/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/jetherng/keras/lib/python3.5/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/jetherng/keras/lib/python3.5/site-packages/ipykernel/kernelapp.py\", line 505, in start\n    self.io_loop.start()\n  File \"/home/jetherng/keras/lib/python3.5/site-packages/tornado/platform/asyncio.py\", line 148, in start\n    self.asyncio_loop.run_forever()\n  File \"/usr/lib/python3.5/asyncio/base_events.py\", line 345, in run_forever\n    self._run_once()\n  File \"/usr/lib/python3.5/asyncio/base_events.py\", line 1312, in _run_once\n    handle._run()\n  File \"/usr/lib/python3.5/asyncio/events.py\", line 125, in _run\n    self._callback(*self._args)\n  File \"/home/jetherng/keras/lib/python3.5/site-packages/tornado/ioloop.py\", line 690, in <lambda>\n    lambda f: self._run_callback(functools.partial(callback, future))\n  File \"/home/jetherng/keras/lib/python3.5/site-packages/tornado/ioloop.py\", line 743, in _run_callback\n    ret = callback()\n  File \"/home/jetherng/keras/lib/python3.5/site-packages/tornado/gen.py\", line 781, in inner\n    self.run()\n  File \"/home/jetherng/keras/lib/python3.5/site-packages/tornado/gen.py\", line 742, in run\n    yielded = self.gen.send(value)\n  File \"/home/jetherng/keras/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 357, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"/home/jetherng/keras/lib/python3.5/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/home/jetherng/keras/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 267, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"/home/jetherng/keras/lib/python3.5/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/home/jetherng/keras/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 534, in execute_request\n    user_expressions, allow_stdin,\n  File \"/home/jetherng/keras/lib/python3.5/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/home/jetherng/keras/lib/python3.5/site-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/jetherng/keras/lib/python3.5/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/jetherng/keras/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2848, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/home/jetherng/keras/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2874, in _run_cell\n    return runner(coro)\n  File \"/home/jetherng/keras/lib/python3.5/site-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/home/jetherng/keras/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 3049, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/jetherng/keras/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 3214, in run_ast_nodes\n    if (yield from self.run_code(code, result)):\n  File \"/home/jetherng/keras/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 3296, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-8-a8abe9461434>\", line 7, in <module>\n    outputs = module(X)\n  File \"/home/jetherng/keras/lib/python3.5/site-packages/tensorflow_hub/module.py\", line 250, in __call__\n    name=name)\n  File \"/home/jetherng/keras/lib/python3.5/site-packages/tensorflow_hub/native_module.py\", line 547, in create_apply_graph\n    import_scope=relative_scope_name)\n  File \"/home/jetherng/keras/lib/python3.5/site-packages/tensorflow/python/training/saver.py\", line 1435, in import_meta_graph\n    meta_graph_or_file, clear_devices, import_scope, **kwargs)[0]\n  File \"/home/jetherng/keras/lib/python3.5/site-packages/tensorflow/python/training/saver.py\", line 1457, in _import_meta_graph_with_return_elements\n    **kwargs))\n  File \"/home/jetherng/keras/lib/python3.5/site-packages/tensorflow/python/framework/meta_graph.py\", line 806, in import_scoped_meta_graph_with_return_elements\n    return_elements=return_elements)\n  File \"/home/jetherng/keras/lib/python3.5/site-packages/tensorflow/python/util/deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"/home/jetherng/keras/lib/python3.5/site-packages/tensorflow/python/framework/importer.py\", line 442, in import_graph_def\n    _ProcessNewOps(graph)\n  File \"/home/jetherng/keras/lib/python3.5/site-packages/tensorflow/python/framework/importer.py\", line 235, in _ProcessNewOps\n    for new_op in graph._add_new_tf_operations(compute_devices=False):  # pylint: disable=protected-access\n  File \"/home/jetherng/keras/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 3433, in _add_new_tf_operations\n    for c_op in c_api_util.new_tf_operations(self)\n  File \"/home/jetherng/keras/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 3433, in <listcomp>\n    for c_op in c_api_util.new_tf_operations(self)\n  File \"/home/jetherng/keras/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 3325, in _create_op_from_tf_operation\n    ret = Operation(c_op, self)\n  File \"/home/jetherng/keras/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 1801, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[74,64,10,112,112] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node module_apply_default/RGB/inception_i3d/Conv3d_1a_7x7/conv_3d/convolution (defined at /home/jetherng/keras/lib/python3.5/site-packages/tensorflow_hub/native_module.py:547) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n"
     ]
    }
   ],
   "source": [
    "batch_size = 2\n",
    "num_steps = int(train_x.shape[0]/batch_size)\n",
    "display_step = 2 #was 2 when achieved test2 accuracy 0.667\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    for epoch in range(10):   #was 10\n",
    "        print(\"epoch {}\".format(epoch))\n",
    "\n",
    "        for step in range(0, num_steps):\n",
    "            batch_x, batch_y = train_x[step:(step+1)*batch_size,...],train_y[step:(step+1)*batch_size,...]\n",
    "\n",
    "                # Run optimization op (backprop)\n",
    "            sess.run(train_op, feed_dict={X: batch_x, labels: batch_y})\n",
    "            if step % display_step == 0 or step == 1:\n",
    "                    # Calculate batch loss and accuracy\n",
    "                loss, acc = sess.run([loss_op, accuracy], feed_dict={X: batch_x,\n",
    "                                                                         labels: batch_y})\n",
    "                print(\"Step \" + str(step) + \", Minibatch Loss= \" + \\\n",
    "                          \"{:.4f}\".format(loss) + \", Training Accuracy= \" + \\\n",
    "                          \"{:.3f}\".format(acc))\n",
    "\n",
    "\n",
    "        print(\"Optimization Finished fpr epoch {}\\n\".format(epoch))\n",
    "        valaccuracy =sess.run(accuracy, feed_dict={X: valid_x,\n",
    "                                              labels:valid_y});\n",
    "        print(\"validation Accuracy: {}\".format(valaccuracy))\n",
    "            \n",
    "        f = open(\"result.txt\",\"a+\")\n",
    "        f.write(\"validation accuracy for epoch {} is {}\\n\".format(epoch,valaccuracy))\n",
    "        f.close()\n",
    "    save_path = saver.save(sess, \"/tmp/model.ckpt\")\n",
    "\n",
    "    del train_x,train_y,valid_x,valid_y\n",
    "    testaccuracy = sess.run(accuracy, feed_dict={X: test_x,\n",
    "                                              labels:test_y})\n",
    "    print(\"Testing accuracy is {} \\n\".format(testaccuracy))\n",
    "    f = open(\"result.txt\",\"a+\")\n",
    "    f.write(\"testing accuracy is {}\\n\".format(testaccuracy))\n",
    "    f.close()\n",
    "    \n",
    "    del test_x,test_y\n",
    "#     print(test2label)\n",
    "#     testaccuracy2 = sess.run(accuracy, feed_dict={X: test2data,\n",
    "#                                               labels:test2label})\n",
    "#     print(\"Testing2 accuracy is {} \\n\".format(testaccuracy2))\n",
    "#     f = open(\"result.txt\",\"a+\")\n",
    "#     f.write(\"testing2 accuracy is {}\\n\".format(testaccuracy2))\n",
    "#     f.close()\n",
    "\n",
    " \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.reset_default_graph()\n",
    "\n",
    "# saver = tf.train.Saver()\n",
    "\n",
    "# with tf.Session() as sess:\n",
    "#     saver = tf.train.import_meta_graph('/tmp/model.ckpt.meta')\n",
    "#     saver.restore(sess, \"/tmp/model.ckpt\")    \n",
    "#     print(\"Model restored.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
